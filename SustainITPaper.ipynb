{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copyright (C) 2017 Leen De Baets (leen.debaets@ugent.be)\n",
    "\n",
    "This file is part of PLAID code repo.\n",
    "\n",
    "This program is free software: you can redistribute it and/or modify\n",
    "it under the terms of the GNU General Public License as published by\n",
    "the Free Software Foundation, either version 3 of the License, or\n",
    "(at your option) any later version.\n",
    "\n",
    "This program is distributed in the hope that it will be useful,\n",
    "but WITHOUT ANY WARRANTY; without even the implied warranty of\n",
    "MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n",
    "GNU General Public License for more details.\n",
    "\n",
    "You should have received a copy of the GNU General Public License\n",
    "along with this program.  If not, see <http://www.gnu.org/licenses/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code is based on the code of Jingkun Goa that analyses the PLAID data. The original code can be found in the notebooks on plaidplug.com or http://nbviewer.jupyter.org/github/jingkungao/PLAID/blob/master/ParseData.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib.font_manager as fm\n",
    "from matplotlib import rc \n",
    "rc('font', family='Times New Roman') \n",
    "\n",
    "import subprocess\n",
    "import numpy as np\n",
    "from random import shuffle\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# functions to read data and meta data\n",
    "def read_data_given_id(path,ids,progress=True,last_offset=0):\n",
    "    '''read data given a list of ids and CSV paths'''\n",
    "    start = datetime.now()\n",
    "    n = len(ids)\n",
    "    if n == 0:\n",
    "        return {}\n",
    "    else:\n",
    "        data = {}\n",
    "        for (i,ist_id) in enumerate(ids, start=1):\n",
    "            if progress and np.mod(i,np.ceil(n/10))==0:\n",
    "                print('%d/%d (%2.0f%s) have been read...\\t time consumed: %ds'\\\n",
    "                      %(i,n,i/n*100,'%',(datetime.now()-start).seconds))\n",
    "            if last_offset==0:\n",
    "                data[ist_id] = np.genfromtxt(path+str(ist_id)+'.csv',delimiter=',',\\\n",
    "                                         names='current,voltage',dtype=(float,float))\n",
    "            else:\n",
    "                p=subprocess.Popen(['tail','-'+str(int(last_offset)),path+str(ist_id)+'.csv'],\\\n",
    "                                   stdout=subprocess.PIPE)\n",
    "                data[ist_id] = np.genfromtxt(p.stdout,delimiter=',',names='current,voltage',\\\n",
    "                                 dtype=(float,float))\n",
    "        print('%d/%d (%2.0f%s) have been read(Done!) \\t time consumed: %ds'\\\n",
    "            %(n,n,100,'%',(datetime.now()-start).seconds))\n",
    "        return data\n",
    "\n",
    "def clean_meta(ist):\n",
    "    '''remove None elements in Meta Data ''' \n",
    "    clean_ist = ist.copy()\n",
    "    for k,v in ist.items():\n",
    "        if len(v) == 0:\n",
    "            del clean_ist[k]\n",
    "    return clean_ist\n",
    "                \n",
    "def parse_meta(meta):\n",
    "    '''parse meta data for easy access'''\n",
    "    M = {}\n",
    "    for m in meta:\n",
    "        for app in m:\n",
    "            M[int(app['id'])] = clean_meta(app['meta'])\n",
    "    return M\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read meta\n",
    "Data_path = '/home/guest/Dataset/PLAID/'\n",
    "csv_path = Data_path + 'CSV/';\n",
    "\n",
    "import json\n",
    "\n",
    "with open(Data_path + 'meta1.json') as data_file:    \n",
    "    meta1 = json.load(data_file)\n",
    "\n",
    "with open(Data_path + 'meta2.json') as data_file:    \n",
    "    meta2 = json.load(data_file)\n",
    "    \n",
    "Meta = parse_meta([meta1,meta2]) # consider PLAID1 and 2\n",
    "#Meta = parse_meta([meta1])\n",
    "#Meta = parse_meta([meta2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of households: 64\n",
      "Number of total measurements:1793\n"
     ]
    }
   ],
   "source": [
    "# read data\n",
    "# applinace types of all instances\n",
    "Types = [x['type'] for x in Meta.values()]\n",
    "# unique appliance types\n",
    "Unq_type = list(set(Types)) \n",
    "Unq_type.sort()\n",
    "IDs_for_read_data = list(Meta.keys())\n",
    "# households of appliances\n",
    "Locs = [x['header']['collection_time']+'_'+x['location'] for x in Meta.values()]\n",
    "# unique households\n",
    "Unq_loc = list(set(Locs))\n",
    "Unq_loc.sort()\n",
    "\n",
    "print('Number of households: %d\\nNumber of total measurements:%d'%(len(Unq_loc),len(Locs)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "179/1793 ( 0%) have been read...\t time consumed: 5s\n",
      "358/1793 ( 0%) have been read...\t time consumed: 10s\n",
      "537/1793 ( 0%) have been read...\t time consumed: 15s\n",
      "716/1793 ( 0%) have been read...\t time consumed: 20s\n",
      "895/1793 ( 0%) have been read...\t time consumed: 24s\n",
      "1074/1793 ( 0%) have been read...\t time consumed: 29s\n",
      "1253/1793 ( 0%) have been read...\t time consumed: 34s\n",
      "1432/1793 ( 0%) have been read...\t time consumed: 39s\n",
      "1611/1793 ( 0%) have been read...\t time consumed: 45s\n",
      "1790/1793 ( 0%) have been read...\t time consumed: 50s\n",
      "1793/1793 (100%) have been read(Done!) \t time consumed: 50s\n"
     ]
    }
   ],
   "source": [
    "npts = 10000\n",
    "Data = read_data_given_id(csv_path,IDs_for_read_data,progress=True, last_offset=npts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of different types: 11\n",
      "number of different households: 64\n"
     ]
    }
   ],
   "source": [
    "type_Ids = {}\n",
    "loc_Ids = {}\n",
    "Mapping = {}\n",
    "n = len(Data)\n",
    "type_label = np.zeros(n,dtype='int')\n",
    "loc_label = np.zeros(n,dtype='int')\n",
    "for (ii,t) in enumerate(Unq_type):\n",
    "    type_Ids[t] = [i-1 for i,j in enumerate(Types,start=1) if j == t]\n",
    "    type_label[type_Ids[t]] = ii\n",
    "    Mapping[ii] = t\n",
    "for (ii,t) in enumerate(Unq_loc):\n",
    "    loc_Ids[t] = [i-1 for i,j in enumerate(Locs,start=1) if j == t]\n",
    "    loc_label[loc_Ids[t]] = ii+1\n",
    "print('number of different types: %d'% len(Unq_type))\n",
    "print('number of different households: %d'% len(Unq_loc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creation of the features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "f1 = one representative period of the voltage and current if the appliance is in steady state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "fs = 30000\n",
    "f0 = 60\n",
    "NS = int(fs/f0) # number of samples per period\n",
    "NP = int(npts/NS) # number of periods for npts\n",
    "\n",
    "# calculate the representative one period of steady state \n",
    "# (mean of the aggregated signals over one cycle)\n",
    "n = len(Data)\n",
    "rep_I = np.empty([n,NS])\n",
    "rep_V = np.empty([n,NS])\n",
    "for i in range(n):\n",
    "    ind = list(Data)[i]\n",
    "    tempI = np.sum(np.reshape(Data[ind]['current'],[NP,NS]),0)/NP\n",
    "    tempV = np.sum(np.reshape(Data[ind]['voltage'],[NP,NS]),0)/NP\n",
    "    # align current to make all samples start from 0 and goes up\n",
    "    ix = np.argsort(np.abs(tempI))\n",
    "    j = 0\n",
    "    while True:\n",
    "        if ix[j]<499 and tempI[ix[j]+1]>tempI[ix[j]]:\n",
    "            real_ix = ix[j]\n",
    "            break\n",
    "        else:\n",
    "            j += 1\n",
    "    rep_I[i,] = np.hstack([tempI[real_ix:],tempI[:real_ix]])\n",
    "    rep_V[i,] = np.hstack([tempV[real_ix:],tempV[:real_ix]])\n",
    "    rep_I[i,] = rep_I[i,] / max(rep_I[i,])\n",
    "    rep_V[i,] = rep_V[i,] / max(rep_V[i,])\n",
    "    \n",
    "f1 = np.hstack([rep_I, rep_V])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "f2 = n-by-n binary image of the VI trajectory with n = 'width' for the steady state behavior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import signal\n",
    "\n",
    "def center(X,w):\n",
    "    minX = np.amin(X)\n",
    "    maxX = np.amax(X)\n",
    "    dist = max(abs(minX),maxX)\n",
    "    X[X<-dist] = -dist\n",
    "    X[X>dist] = dist\n",
    "    d = (maxX-minX)/(w-1)\n",
    "    return (X,d)\n",
    "    \n",
    "def get_img_from_VI(V, I, width,hard_threshold=False,para=.5):\n",
    "    '''Get images from VI, hard_threshold, set para as threshold to cut off,5-10\n",
    "    soft_threshold, set para to .1-.5 to shrink the intensity'''\n",
    "    # center the current and voltage, get the size resolution of mesh given width\n",
    "    d = V.shape[0]\n",
    "    # doing interploation if number of points is less than width*2\n",
    "    if d<2* width:\n",
    "        newI = np.hstack([V, V[0]])\n",
    "        newV = np.hstack([I, I[0]])\n",
    "        oldt = np.linspace(0,d,d+1)\n",
    "        newt = np.linspace(0,d,2*width)\n",
    "        I = np.interp(newt,oldt,newI)\n",
    "        V = np.interp(newt,oldt,newV)\n",
    "        \n",
    "    (I,d_c)  = center(I,width)\n",
    "    (V,d_v)  = center(V,width)\n",
    "    \n",
    "    #  find the index where the VI goes through in current-voltage axis\n",
    "    ind_c = np.ceil((I-np.amin(I))/d_c)\n",
    "    ind_v = np.ceil((V-np.amin(V))/d_v)\n",
    "    ind_c[ind_c==width] = width-1\n",
    "    ind_v[ind_v==width] = width-1\n",
    "    \n",
    "    Img = np.zeros((width,width))\n",
    "    \n",
    "    for i in range(len(I)):\n",
    "        Img[int(ind_c[i]),int(width-ind_v[i]-1)] += 1\n",
    "    \n",
    "    if hard_threshold:\n",
    "        Img[Img<para] = 0\n",
    "        Img[Img!=0] = 1\n",
    "        return Img\n",
    "    else:\n",
    "        return (Img/np.max(Img))**para\n",
    "    \n",
    "n = len(Data)\n",
    "width = 16\n",
    "\n",
    "Imgs = np.empty((n,width,width), dtype=np.float64)\n",
    "for i in range(n):\n",
    "    Imgs[i,:,:] = get_img_from_VI(rep_V[i,], rep_I[i,], width,True,1)\n",
    "f2=np.reshape(Imgs,(n,width*width))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "f3 = the representative cycle for current and voltage if the appliance is in steady state, is downsampled by creating bins and counting the amount of samples belonging to that bin."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "num = 20 # number of bins\n",
    "\n",
    "def get_BinF(X,num):\n",
    "    '''X should be nd array of size N*P, the output will be N*num'''\n",
    "    (N,P) = X.shape\n",
    "    newP = int(np.floor(P/num)*num)\n",
    "    newX = np.reshape(X[:,:newP],[N,num,newP/num])\n",
    "    BinF = np.sum(newX,2)\n",
    "    return BinF\n",
    "\n",
    "BinF_I = get_BinF(rep_I,num)    \n",
    "BinF_V = get_BinF(rep_V,num)  \n",
    "\n",
    "f3 = np.hstack([BinF_I,BinF_V])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "f4 = one representative period of the current if the appliance is in steady state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "f4= rep_I"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "f5 = real and reactive power "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = len(Data)\n",
    "f5 = np.empty([n,2])\n",
    "f5[:,0] = np.mean(rep_I*rep_V,1) # real power\n",
    "for i in range(n):\n",
    "    tempI = Data[i+1]['current'][NS+1:]\n",
    "    tempV = Data[i+1]['voltage'][NS-NS/4+1:-NS/4]\n",
    "    f5[i,1] = np.sum(tempI*tempV)/(npts-NS) # reactive power"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "f6 = the harmonics of the power"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "order = 21\n",
    "p = (order-1)//2+1 # number of harmonics to be extracted\n",
    "harmonics = np.linspace(1,order,num=p)\n",
    "fs = 30000\n",
    "npts = 10000\n",
    "f0 = 120 # for power\n",
    "\n",
    "f6 = np.empty([n,p])\n",
    "\n",
    "for i in range(n):\n",
    "    temp_P = Data[i+1]['current']*Data[i+1]['voltage']\n",
    "    y = np.abs(np.fft.fft(temp_P))\n",
    "    h = 40*harmonics+1\n",
    "    h = h.astype(int)\n",
    "    f6[i,] =y[h]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from itertools import cycle\n",
    "\n",
    "from sklearn import svm, datasets\n",
    "from sklearn.metrics import roc_curve, auc, f1_score, accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from scipy import interp\n",
    "from sklearn.base import clone\n",
    "from sklearn import preprocessing\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.lda import LDA\n",
    "from sklearn.qda import QDA\n",
    "from sklearn import tree\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "\n",
    "from imblearn.over_sampling import RandomOverSampler, SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler \n",
    "\n",
    "from blagging import BlaggingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors=1)\n",
    "gnb = GaussianNB()\n",
    "logistic = LogisticRegression(C=1e5)\n",
    "lda = LDA(solver='lsqr', shrinkage='auto')\n",
    "qda = QDA()\n",
    "dTree = tree.DecisionTreeClassifier(max_depth=10)\n",
    "rForest = RandomForestClassifier(max_depth=10,n_estimators=20)\n",
    "svm = SVC(kernel='linear', probability=True)\n",
    "adaBoost = AdaBoostClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "knn\n",
      "gnb\n",
      "logistic\n",
      "lda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leen/virtualEnv/myenv/local/lib/python2.7/site-packages/sklearn/discriminant_analysis.py:455: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "qda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leen/virtualEnv/myenv/local/lib/python2.7/site-packages/sklearn/discriminant_analysis.py:695: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/home/leen/virtualEnv/myenv/local/lib/python2.7/site-packages/sklearn/multiclass.py:352: RuntimeWarning: invalid value encountered in divide\n",
      "  Y /= np.sum(Y, axis=1)[:, np.newaxis]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dTree\n",
      "rForest\n",
      "svm\n",
      "adaBoost\n",
      "1\n",
      "knn\n",
      "gnb\n",
      "logistic\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leen/virtualEnv/myenv/local/lib/python2.7/site-packages/sklearn/linear_model/base.py:352: RuntimeWarning: overflow encountered in exp\n",
      "  np.exp(prob, prob)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lda\n",
      "qda\n",
      "dTree\n",
      "rForest\n",
      "svm\n",
      "adaBoost\n",
      "2\n",
      "knn\n",
      "gnb\n",
      "logistic\n",
      "lda\n",
      "qda\n"
     ]
    }
   ],
   "source": [
    "# choose classifier\n",
    "n = len(Unq_loc)\n",
    "\n",
    "# train the classifier with 11 outputs and store the result\n",
    "y_proba_concat = {}\n",
    "y_test_concat = {}\n",
    "y_pred_concat = {}\n",
    "\n",
    "for cname in ['knn', 'gnb', 'logistic', 'lda', 'qda', 'dTree', 'rForest', 'svm', 'adaBoost']:\n",
    "    y_proba_concat[cname] = dict()\n",
    "    y_test_concat[cname] = dict()\n",
    "    y_pred_concat[cname] = dict()\n",
    "\n",
    "    for k in ['normal','over','under','smote','blagging','weighted']:\n",
    "        y_proba_concat[cname][k] = np.empty((0,11)) \n",
    "        y_test_concat[cname][k] = np.empty((0))\n",
    "        y_pred_concat[cname][k] = np.empty((0))\n",
    "\n",
    "amount_houses_test = 1\n",
    "for i in range(len(Unq_loc)):\n",
    "    print(i)\n",
    "    ix_train = [j for j in range(len(loc_label)) if loc_label[j] not in range(i+1,i+amount_houses_test + 1)]\n",
    "    X_train = f2[ix_train]\n",
    "    y_train = type_label[ix_train]\n",
    "\n",
    "    ix_test = [j for j in range(len(loc_label)) if loc_label[j] in range(i+1,i+amount_houses_test + 1) and type_label[j] in y_train]\n",
    "    X_test = f2[ix_test]\n",
    "    y_test = type_label[ix_test]\n",
    "    \n",
    "    # oversample the train set, ALWAYS leave the test set as normal!\n",
    "    ros = RandomOverSampler(ratio='all')\n",
    "    X_over, y_over = ros.fit_sample(X_train, y_train)\n",
    "    \n",
    "    # undersample the train set\n",
    "    ros = RandomUnderSampler(ratio='all')\n",
    "    X_under, y_under = ros.fit_sample(X_train, y_train)\n",
    "    \n",
    "    # synthesize examples\n",
    "    ros = SMOTE(ratio='all')\n",
    "    X_smote, y_smote = ros.fit_sample(X_train, y_train)\n",
    "    \n",
    "    # uncomment this if feature is binary\n",
    "    #id2 = np.where(X_smote > 0)\n",
    "    #id3 = np.where(X_smote < 0)\n",
    "\n",
    "    #X_smote[id2] = 1\n",
    "    #X_smote[id3] = 0\n",
    "    \n",
    "    for c, cname in zip([knn, gnb, logistic, lda, qda, dTree, rForest, svm, adaBoost], ['knn', 'gnb', 'logistic', 'lda', 'qda', 'dTree', 'rForest', 'svm', 'adaBoost']):\n",
    "        # normal\n",
    "        print(cname)\n",
    "        classifier = clone(c)\n",
    "        classifier.fit(X_train, y_train)\n",
    "        y_proba = classifier.predict_proba(X_test)\n",
    "        y_pred = classifier.predict(X_test)    \n",
    "        y_proba_concat[cname]['normal'] = np.concatenate((y_proba_concat[cname]['normal'],y_proba))\n",
    "        y_test_concat[cname]['normal'] = np.concatenate((y_test_concat[cname]['normal'],y_test))\n",
    "        y_pred_concat[cname]['normal'] = np.concatenate((y_pred_concat[cname]['normal'],y_pred))\n",
    "\n",
    "        # oversample\n",
    "        classifier = clone(c)\n",
    "        classifier.fit(X_over, y_over)\n",
    "        y_proba = classifier.predict_proba(X_test)\n",
    "        y_pred = classifier.predict(X_test)    \n",
    "        y_proba_concat[cname]['over'] = np.concatenate((y_proba_concat[cname]['over'],y_proba))\n",
    "        y_test_concat[cname]['over'] = np.concatenate((y_test_concat[cname]['over'],y_test))\n",
    "        y_pred_concat[cname]['over'] = np.concatenate((y_pred_concat[cname]['over'],y_pred))\n",
    "\n",
    "        # undersample\n",
    "        classifier = clone(c)\n",
    "        classifier.fit(X_under, y_under)\n",
    "        y_proba = classifier.predict_proba(X_test)\n",
    "        y_pred = classifier.predict(X_test)    \n",
    "        y_proba_concat[cname]['under'] = np.concatenate((y_proba_concat[cname]['under'],y_proba))\n",
    "        y_test_concat[cname]['under'] = np.concatenate((y_test_concat[cname]['under'],y_test))\n",
    "        y_pred_concat[cname]['under'] = np.concatenate((y_pred_concat[cname]['under'],y_pred))\n",
    "\n",
    "        # smote\n",
    "        classifier = clone(c)\n",
    "        classifier.fit(X_smote, y_smote)\n",
    "        y_proba = classifier.predict_proba(X_test)\n",
    "        y_pred = classifier.predict(X_test)    \n",
    "        y_proba_concat[cname]['smote'] = np.concatenate((y_proba_concat[cname]['smote'],y_proba))\n",
    "        y_test_concat[cname]['smote'] = np.concatenate((y_test_concat[cname]['smote'],y_test))\n",
    "        y_pred_concat[cname]['smote'] = np.concatenate((y_pred_concat[cname]['smote'],y_pred))\n",
    "\n",
    "        # Blagging\n",
    "        classifier = clone(c)\n",
    "        bc = OneVsRestClassifier(BlaggingClassifier(classifier))\n",
    "        bc.fit(X_train,y_train)\n",
    "        y_proba = bc.predict_proba(X_test)\n",
    "        y_pred = bc.predict(X_test)\n",
    "        y_proba_concat[cname]['blagging'] = np.concatenate((y_proba_concat[cname]['blagging'],y_proba))\n",
    "        y_test_concat[cname]['blagging'] = np.concatenate((y_test_concat[cname]['blagging'],y_test))\n",
    "        y_pred_concat[cname]['blagging'] = np.concatenate((y_pred_concat[cname]['blagging'],y_pred))\n",
    "        \n",
    "        # weighted\n",
    "        if cname in  ['logistic', 'dTree', 'rForest', 'svm']:\n",
    "            classifier = clone(c)\n",
    "            classifier.set_params(class_weight = 'balanced')\n",
    "            classifier.fit(X_train, y_train)\n",
    "            y_proba = classifier.predict_proba(X_test)\n",
    "            y_pred = classifier.predict(X_test)    \n",
    "            y_proba_concat[cname]['weighted'] = np.concatenate((y_proba_concat[cname]['weighted'],y_proba))\n",
    "            y_test_concat[cname]['weighted'] = np.concatenate((y_test_concat[cname]['weighted'],y_test))\n",
    "            y_pred_concat[cname]['weighted'] = np.concatenate((y_pred_concat[cname]['weighted'],y_pred))\n",
    "\n",
    "c = np.unique(y_test_concat['logistic']['normal'])\n",
    "for cname in  ['knn', 'gnb', 'logistic', 'lda', 'qda', 'dTree', 'rForest', 'svm', 'adaBoost']:\n",
    "    for k in ['normal','over','under','smote','blagging','weighted']:\n",
    "        if k == 'weighted' and cname not in  ['logistic', 'dTree', 'rForest', 'svm']:\n",
    "            continue\n",
    "        else:\n",
    "            y_test_concat[cname][k] = label_binarize(y_test_concat[cname][k], classes=c)\n",
    "            y_pred_concat[cname][k] = label_binarize(y_pred_concat[cname][k], classes=c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fpr = dict()\n",
    "tpr = dict()\n",
    "thresholds = dict()\n",
    "roc_auc = dict()\n",
    "accuracy = dict()\n",
    "f_measure = dict()\n",
    "\n",
    "for cname in ['knn', 'gnb', 'logistic', 'lda', 'qda', 'dTree', 'rForest', 'svm', 'adaBoost']:\n",
    "    fpr[cname] = dict()\n",
    "    tpr[cname] = dict()\n",
    "    thresholds[cname] = dict()\n",
    "    roc_auc[cname] = dict()\n",
    "    accuracy[cname] = dict()\n",
    "    f_measure[cname] = dict()\n",
    "    for k in ['normal','over','under','smote','blagging','weighted']:\n",
    "        if k == 'weighted' and cname not in  ['logistic', 'dTree', 'rForest', 'svm']:\n",
    "            continue\n",
    "        else:\n",
    "            # Compute ROC curve and ROC area for each class\n",
    "            fpr[cname][k] = dict()\n",
    "            tpr[cname][k] = dict()\n",
    "            thresholds[cname][k] = dict()\n",
    "            roc_auc[cname][k] = dict()\n",
    "            accuracy[cname][k] = dict()\n",
    "            f_measure[cname][k] = dict()\n",
    "            for i in range(11):\n",
    "                fpr[cname][k][Mapping[i]], tpr[cname][k][Mapping[i]], thresholds[cname][k][Mapping[i]] = roc_curve(y_test_concat[cname][k][:, i], np.nan_to_num(y_proba_concat[cname][k][:, i]))\n",
    "                roc_auc[cname][k][Mapping[i]] = auc(fpr[cname][k][Mapping[i]], tpr[cname][k][Mapping[i]])\n",
    "\n",
    "                accuracy[cname][k][Mapping[i]] = accuracy_score(y_test_concat[cname][k][:, i], y_pred_concat[cname][k][:, i])\n",
    "                f_measure[cname][k][Mapping[i]] = f1_score(y_test_concat[cname][k][:,i], y_pred_concat[cname][k][:,i])\n",
    "\n",
    "            # Compute micro-average ROC curve and ROC area\n",
    "            fpr[cname][k][\"micro\"], tpr[cname][k][\"micro\"], thresholds[cname][k][\"micro\"] = roc_curve(y_test_concat[cname][k].ravel(), np.nan_to_num(y_proba_concat[cname][k].ravel()))\n",
    "            roc_auc[cname][k][\"micro\"] = auc(fpr[cname][k][\"micro\"], tpr[cname][k][\"micro\"])\n",
    "            accuracy[cname][k][\"micro\"] = accuracy_score(y_test_concat[cname][k].ravel(), y_pred_concat[cname][k].ravel())\n",
    "            f_measure[cname][k][\"micro\"] = f1_score(y_test_concat[cname][k].ravel(), y_pred_concat[cname][k].ravel())\n",
    "\n",
    "\n",
    "            # First aggregate all false positive rates\n",
    "            all_fpr = np.unique(np.concatenate([fpr[cname][k][Mapping[i]] for i in range(11)]))\n",
    "\n",
    "            # Then interpolate all ROC curves at this points\n",
    "            mean_tpr = np.zeros_like(all_fpr)\n",
    "            mean_acc = 0\n",
    "            mean_f = 0\n",
    "            for i in range(11):\n",
    "                mean_tpr += interp(all_fpr, fpr[cname][k][Mapping[i]], tpr[cname][k][Mapping[i]])\n",
    "                mean_acc += accuracy[cname][k][Mapping[i]]\n",
    "                mean_f += f_measure[cname][k][Mapping[i]]\n",
    "\n",
    "            # Finally average it and compute AUC\n",
    "            mean_tpr /= 11\n",
    "\n",
    "            fpr[cname][k][\"macro\"] = all_fpr\n",
    "            tpr[cname][k][\"macro\"] = mean_tpr\n",
    "            roc_auc[cname][k][\"macro\"] = auc(fpr[cname][k][\"macro\"], tpr[cname][k][\"macro\"])\n",
    "            accuracy[cname][k][\"macro\"] = mean_acc / 11\n",
    "            f_measure[cname][k][\"macro\"] = mean_f / 11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "\n",
    "i_values = Mapping.values()[:] \n",
    "i_values.extend(['macro', 'micro'])\n",
    "\n",
    "for i in i_values:\n",
    "    to_print = \"\"\n",
    "    to_print1 = \"\"\n",
    "    to_print2 = \"\"\n",
    "    for  cname in  ['knn', 'gnb', 'logistic', 'lda', 'qda', 'dTree', 'rForest', 'svm', 'adaBoost']:\n",
    "        to_print += str(cname) + \" \\t \"\n",
    "        for k in ['normal','over','under','smote','blagging','weighted']:     \n",
    "            if k == 'weighted' and cname not in  ['logistic', 'dTree', 'rForest', 'svm']:\n",
    "                to_print += \"\"\n",
    "                continue\n",
    "            else:\n",
    "                to_print += \"{0:.2f}\".format(roc_auc[cname][k][i] * 100 - roc_auc[cname]['normal'][i] * 100 ) + \"$ \\t $\"\n",
    "\n",
    "        to_print = to_print[:-3]\n",
    "        to_print += \"\\\\\\\\ \\n\"\n",
    "\n",
    "    print(\"{} ({})\".format(i, sum(np.array(Types) == i)) )\n",
    "    print(\"AUC\")\n",
    "    print(\"# h \\tnormal\\tover\\tunder\\tsmote\\tblagging\\tweighted\")\n",
    "    print(to_print)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Less training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "knn\n",
      "gnb\n",
      "logistic\n",
      "lda\n",
      "qda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leen/virtualEnv/myenv/local/lib/python2.7/site-packages/sklearn/discriminant_analysis.py:719: RuntimeWarning: divide by zero encountered in power\n",
      "  X2 = np.dot(Xm, R * (S ** (-0.5)))\n",
      "/home/leen/virtualEnv/myenv/local/lib/python2.7/site-packages/sklearn/discriminant_analysis.py:719: RuntimeWarning: invalid value encountered in multiply\n",
      "  X2 = np.dot(Xm, R * (S ** (-0.5)))\n",
      "/home/leen/virtualEnv/myenv/local/lib/python2.7/site-packages/sklearn/discriminant_analysis.py:722: RuntimeWarning: divide by zero encountered in log\n",
      "  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dTree\n",
      "rForest\n",
      "svm\n",
      "adaBoost\n",
      "1\n",
      "knn\n",
      "gnb\n",
      "logistic\n",
      "lda\n",
      "qda\n",
      "dTree\n",
      "rForest\n",
      "svm\n",
      "adaBoost\n",
      "2\n",
      "knn\n",
      "gnb\n",
      "logistic\n",
      "lda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leen/virtualEnv/myenv/local/lib/python2.7/site-packages/sklearn/discriminant_analysis.py:523: RuntimeWarning: overflow encountered in exp\n",
      "  np.exp(prob, prob)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "qda\n",
      "dTree\n",
      "rForest\n",
      "svm\n",
      "adaBoost\n",
      "3\n",
      "knn\n",
      "gnb\n",
      "logistic\n",
      "lda\n",
      "qda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leen/virtualEnv/myenv/local/lib/python2.7/site-packages/sklearn/discriminant_analysis.py:720: RuntimeWarning: overflow encountered in square\n",
      "  norm2.append(np.sum(X2 ** 2, 1))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dTree\n",
      "rForest\n",
      "svm\n",
      "adaBoost\n",
      "4\n",
      "knn\n",
      "gnb\n",
      "logistic\n",
      "lda\n",
      "qda\n",
      "dTree\n",
      "rForest\n",
      "svm\n",
      "adaBoost\n",
      "5\n",
      "knn\n",
      "gnb\n",
      "logistic\n",
      "lda\n",
      "qda\n",
      "dTree\n",
      "rForest\n",
      "svm\n",
      "adaBoost\n",
      "6\n",
      "knn\n",
      "gnb\n",
      "logistic\n",
      "lda\n",
      "qda\n",
      "dTree\n",
      "rForest\n",
      "svm\n",
      "adaBoost\n",
      "7\n",
      "knn\n",
      "gnb\n",
      "logistic\n",
      "lda\n",
      "qda\n",
      "dTree\n",
      "rForest\n",
      "svm\n",
      "adaBoost\n",
      "8\n",
      "knn\n",
      "gnb\n",
      "logistic\n",
      "lda\n",
      "qda\n",
      "dTree\n",
      "rForest\n",
      "svm\n",
      "adaBoost\n",
      "9\n",
      "knn\n",
      "gnb\n",
      "logistic\n",
      "lda\n",
      "qda\n",
      "dTree\n",
      "rForest\n",
      "svm\n",
      "adaBoost\n",
      "10\n",
      "knn\n",
      "gnb\n",
      "logistic\n",
      "lda\n",
      "qda\n",
      "dTree\n",
      "rForest\n",
      "svm\n",
      "adaBoost\n",
      "11\n",
      "knn\n",
      "gnb\n",
      "logistic\n",
      "lda\n",
      "qda\n",
      "dTree\n",
      "rForest\n",
      "svm\n",
      "adaBoost\n",
      "12\n",
      "knn\n",
      "gnb\n",
      "logistic\n",
      "lda\n",
      "qda\n",
      "dTree\n",
      "rForest\n",
      "svm\n",
      "adaBoost\n",
      "13\n",
      "knn\n",
      "gnb\n",
      "logistic\n",
      "lda\n",
      "qda\n",
      "dTree\n",
      "rForest\n",
      "svm\n",
      "adaBoost\n",
      "14\n",
      "knn\n",
      "gnb\n",
      "logistic\n",
      "lda\n",
      "qda\n",
      "dTree\n",
      "rForest\n",
      "svm\n",
      "adaBoost\n",
      "15\n",
      "knn\n",
      "gnb\n",
      "logistic\n",
      "lda\n",
      "qda\n",
      "dTree\n",
      "rForest\n",
      "svm\n",
      "adaBoost\n",
      "16\n",
      "knn\n",
      "gnb\n",
      "logistic\n",
      "lda\n",
      "qda\n",
      "dTree\n",
      "rForest\n",
      "svm\n",
      "adaBoost\n",
      "17\n",
      "knn\n",
      "gnb\n",
      "logistic\n",
      "lda\n",
      "qda\n",
      "dTree\n",
      "rForest\n",
      "svm\n",
      "adaBoost\n",
      "18\n",
      "knn\n",
      "gnb\n",
      "logistic\n",
      "lda\n",
      "qda\n",
      "dTree\n",
      "rForest\n",
      "svm\n",
      "adaBoost\n",
      "19\n",
      "knn\n",
      "gnb\n",
      "logistic\n",
      "lda\n",
      "qda\n",
      "dTree\n",
      "rForest\n",
      "svm\n",
      "adaBoost\n",
      "20\n",
      "knn\n",
      "gnb\n",
      "logistic\n",
      "lda\n",
      "qda\n",
      "dTree\n",
      "rForest\n",
      "svm\n",
      "adaBoost\n",
      "21\n",
      "knn\n",
      "gnb\n",
      "logistic\n",
      "lda\n",
      "qda\n",
      "dTree\n",
      "rForest\n",
      "svm\n",
      "adaBoost\n",
      "22\n",
      "knn\n",
      "gnb\n",
      "logistic\n",
      "lda\n",
      "qda\n",
      "dTree\n",
      "rForest\n",
      "svm\n",
      "adaBoost\n",
      "23\n",
      "knn\n",
      "gnb\n",
      "logistic\n",
      "lda\n",
      "qda\n",
      "dTree\n",
      "rForest\n",
      "svm\n",
      "adaBoost\n",
      "24\n",
      "knn\n",
      "gnb\n",
      "logistic\n",
      "lda\n",
      "qda\n",
      "dTree\n",
      "rForest\n",
      "svm\n",
      "adaBoost\n",
      "25\n",
      "knn\n",
      "gnb\n",
      "logistic\n",
      "lda\n",
      "qda\n",
      "dTree\n",
      "rForest\n",
      "svm\n",
      "adaBoost\n",
      "26\n",
      "knn\n",
      "gnb\n",
      "logistic\n",
      "lda\n",
      "qda\n",
      "dTree\n",
      "rForest\n",
      "svm\n",
      "adaBoost\n",
      "27\n",
      "knn\n",
      "gnb\n",
      "logistic\n",
      "lda\n",
      "qda\n",
      "dTree\n",
      "rForest\n",
      "svm\n",
      "adaBoost\n",
      "28\n",
      "knn\n",
      "gnb\n",
      "logistic\n",
      "lda\n",
      "qda\n",
      "dTree\n",
      "rForest\n",
      "svm\n",
      "adaBoost\n",
      "29\n",
      "knn\n",
      "gnb\n",
      "logistic\n",
      "lda\n",
      "qda\n",
      "dTree\n",
      "rForest\n",
      "svm\n",
      "adaBoost\n",
      "30\n",
      "knn\n",
      "gnb\n",
      "logistic\n",
      "lda\n",
      "qda\n",
      "dTree\n",
      "rForest\n",
      "svm\n",
      "adaBoost\n",
      "31\n",
      "knn\n",
      "gnb\n",
      "logistic\n",
      "lda\n",
      "qda\n",
      "dTree\n",
      "rForest\n",
      "svm\n",
      "adaBoost\n",
      "32\n",
      "knn\n",
      "gnb\n",
      "logistic\n",
      "lda\n",
      "qda\n",
      "dTree\n",
      "rForest\n",
      "svm\n",
      "adaBoost\n",
      "33\n",
      "knn\n",
      "gnb\n",
      "logistic\n",
      "lda\n",
      "qda\n",
      "dTree\n",
      "rForest\n",
      "svm\n",
      "adaBoost\n",
      "34\n",
      "knn\n",
      "gnb\n",
      "logistic\n",
      "lda\n",
      "qda\n",
      "dTree\n",
      "rForest\n",
      "svm\n",
      "adaBoost\n",
      "35\n",
      "knn\n",
      "gnb\n",
      "logistic\n",
      "lda\n",
      "qda\n",
      "dTree\n",
      "rForest\n",
      "svm\n",
      "adaBoost\n",
      "36\n",
      "knn\n",
      "gnb\n",
      "logistic\n",
      "lda\n",
      "qda\n",
      "dTree\n",
      "rForest\n",
      "svm\n",
      "adaBoost\n",
      "37\n",
      "knn\n",
      "gnb\n",
      "logistic\n",
      "lda\n",
      "qda\n",
      "dTree\n",
      "rForest\n",
      "svm\n",
      "adaBoost\n",
      "38\n",
      "knn\n",
      "gnb\n",
      "logistic\n",
      "lda\n",
      "qda\n",
      "dTree\n",
      "rForest\n",
      "svm\n",
      "adaBoost\n",
      "39\n",
      "knn\n",
      "gnb\n",
      "logistic\n",
      "lda\n",
      "qda\n",
      "dTree\n",
      "rForest\n",
      "svm\n",
      "adaBoost\n",
      "40\n",
      "knn\n",
      "gnb\n",
      "logistic\n",
      "lda\n",
      "qda\n",
      "dTree\n",
      "rForest\n",
      "svm\n",
      "adaBoost\n",
      "41\n",
      "knn\n",
      "gnb\n",
      "logistic\n",
      "lda\n",
      "qda\n",
      "dTree\n",
      "rForest\n",
      "svm\n",
      "adaBoost\n",
      "42\n",
      "knn\n",
      "gnb\n",
      "logistic\n",
      "lda\n",
      "qda\n",
      "dTree\n",
      "rForest\n",
      "svm\n",
      "adaBoost\n",
      "43\n",
      "knn\n",
      "gnb\n",
      "logistic\n",
      "lda\n",
      "qda\n",
      "dTree\n",
      "rForest\n",
      "svm\n",
      "adaBoost\n",
      "44\n",
      "knn\n",
      "gnb\n",
      "logistic\n",
      "lda\n",
      "qda\n",
      "dTree\n",
      "rForest\n",
      "svm\n",
      "adaBoost\n",
      "45\n",
      "knn\n",
      "gnb\n",
      "logistic\n",
      "lda\n",
      "qda\n",
      "dTree\n",
      "rForest\n",
      "svm\n",
      "adaBoost\n",
      "46\n",
      "knn\n",
      "gnb\n",
      "logistic\n",
      "lda\n",
      "qda\n",
      "dTree\n",
      "rForest\n",
      "svm\n",
      "adaBoost\n",
      "47\n",
      "knn\n",
      "gnb\n",
      "logistic\n",
      "lda\n",
      "qda\n",
      "dTree\n",
      "rForest\n",
      "svm\n",
      "adaBoost\n",
      "48\n",
      "knn\n",
      "gnb\n",
      "logistic\n",
      "lda\n",
      "qda\n",
      "dTree\n",
      "rForest\n",
      "svm\n",
      "adaBoost\n",
      "49\n",
      "knn\n",
      "gnb\n",
      "logistic\n",
      "lda\n",
      "qda\n",
      "dTree\n",
      "rForest\n",
      "svm\n",
      "adaBoost\n",
      "50\n",
      "knn\n",
      "gnb\n",
      "logistic\n",
      "lda\n",
      "qda\n",
      "dTree\n",
      "rForest\n",
      "svm\n",
      "adaBoost\n",
      "51\n",
      "knn\n",
      "gnb\n",
      "logistic\n",
      "lda\n",
      "qda\n",
      "dTree\n",
      "rForest\n",
      "svm\n",
      "adaBoost\n",
      "52\n",
      "knn\n",
      "gnb\n",
      "logistic\n",
      "lda\n",
      "qda\n",
      "dTree\n",
      "rForest\n",
      "svm\n",
      "adaBoost\n",
      "53\n",
      "knn\n",
      "gnb\n",
      "logistic\n",
      "lda\n",
      "qda\n",
      "dTree\n",
      "rForest\n",
      "svm\n",
      "adaBoost\n",
      "54\n",
      "knn\n",
      "gnb\n",
      "logistic\n",
      "lda\n",
      "qda\n",
      "dTree\n",
      "rForest\n",
      "svm\n",
      "adaBoost\n",
      "55\n",
      "knn\n",
      "gnb\n",
      "logistic\n",
      "lda\n",
      "qda\n",
      "dTree\n",
      "rForest\n",
      "svm\n",
      "adaBoost\n",
      "56\n",
      "knn\n",
      "gnb\n",
      "logistic\n",
      "lda\n",
      "qda\n",
      "dTree\n",
      "rForest\n",
      "svm\n",
      "adaBoost\n",
      "57\n",
      "knn\n",
      "gnb\n",
      "logistic\n",
      "lda\n",
      "qda\n",
      "dTree\n",
      "rForest\n",
      "svm\n",
      "adaBoost\n",
      "58\n",
      "knn\n",
      "gnb\n",
      "logistic\n",
      "lda\n",
      "qda\n",
      "dTree\n",
      "rForest\n",
      "svm\n",
      "adaBoost\n",
      "59\n",
      "knn\n",
      "gnb\n",
      "logistic\n",
      "lda\n",
      "qda\n",
      "dTree\n",
      "rForest\n",
      "svm\n",
      "adaBoost\n",
      "60\n",
      "knn\n",
      "gnb\n",
      "logistic\n",
      "lda\n",
      "qda\n",
      "dTree\n",
      "rForest\n",
      "svm\n",
      "adaBoost\n",
      "61\n",
      "knn\n",
      "gnb\n",
      "logistic\n",
      "lda\n",
      "qda\n",
      "dTree\n",
      "rForest\n",
      "svm\n",
      "adaBoost\n",
      "62\n",
      "knn\n",
      "gnb\n",
      "logistic\n",
      "lda\n",
      "qda\n",
      "dTree\n",
      "rForest\n",
      "svm\n",
      "adaBoost\n",
      "63\n",
      "knn\n",
      "gnb\n",
      "logistic\n",
      "lda\n",
      "qda\n",
      "dTree\n",
      "rForest\n",
      "svm\n",
      "adaBoost\n"
     ]
    }
   ],
   "source": [
    "# choose classifier\n",
    "n = len(Unq_loc)\n",
    "\n",
    "# train the classifier with 11 outputs and store the result\n",
    "y_proba_concat = {}\n",
    "y_test_concat = {}\n",
    "y_pred_concat = {}\n",
    "\n",
    "for cname in ['knn', 'gnb', 'logistic', 'lda', 'qda', 'dTree', 'rForest', 'svm', 'adaBoost']:\n",
    "    y_proba_concat[cname] = dict()\n",
    "    y_test_concat[cname] = dict()\n",
    "    y_pred_concat[cname] = dict()\n",
    "\n",
    "    for k in ['normal','over','under','smote','blagging','weighted']:\n",
    "        y_proba_concat[cname][k] = np.empty((0,11)) \n",
    "        y_test_concat[cname][k] = np.empty((0))\n",
    "        y_pred_concat[cname][k] = np.empty((0))\n",
    "\n",
    "amount_houses_test = 1\n",
    "for i in range(len(Unq_loc)):\n",
    "    print(i)\n",
    "    \n",
    "    ix_train = []\n",
    "    collected = {}\n",
    "    for j in range(len(loc_label)):\n",
    "        if loc_label[j] not in range(i+1,i+amount_houses_test + 1):\n",
    "            # j belongs to a train house:\n",
    "            if loc_label[j] not in collected:\n",
    "                collected[loc_label[j]] = []\n",
    "            # check if appliance type of index j is already collected\n",
    "            if type_label[j] not in collected[loc_label[j]]:\n",
    "                collected[loc_label[j]].append(type_label[j])\n",
    "                ix_train.append(j)\n",
    "\n",
    "    \n",
    "    X_train = f2[ix_train]\n",
    "    y_train = type_label[ix_train]\n",
    "\n",
    "    ix_test = [j for j in range(len(loc_label)) if loc_label[j] in range(i+1,i+amount_houses_test + 1) and type_label[j] in y_train]\n",
    "    X_test = f2[ix_test]\n",
    "    y_test = type_label[ix_test]\n",
    "    \n",
    "    # oversample the train set, ALWAYS leave the test set as normal!\n",
    "    ros = RandomOverSampler(ratio='all')\n",
    "    X_over, y_over = ros.fit_sample(X_train, y_train)\n",
    "    \n",
    "    # undersample the train set\n",
    "    ros = RandomUnderSampler(ratio='all')\n",
    "    X_under, y_under = ros.fit_sample(X_train, y_train)\n",
    "    \n",
    "    # synthesize examples\n",
    "    ros = SMOTE(ratio='all')\n",
    "    X_smote, y_smote = ros.fit_sample(X_train, y_train)\n",
    "    \n",
    "    # uncomment this if feature is binary\n",
    "    #id2 = np.where(X_smote > 0)\n",
    "    #id3 = np.where(X_smote < 0)\n",
    "\n",
    "    #X_smote[id2] = 1\n",
    "    #X_smote[id3] = 0\n",
    "    \n",
    "    for c, cname in zip([knn, gnb, logistic, lda, qda, dTree, rForest, svm, adaBoost], ['knn', 'gnb', 'logistic', 'lda', 'qda', 'dTree', 'rForest', 'svm', 'adaBoost']):\n",
    "        # normal\n",
    "        print(cname)\n",
    "        classifier = clone(c)\n",
    "        classifier.fit(X_train, y_train)\n",
    "        y_proba = classifier.predict_proba(X_test)\n",
    "        y_pred = classifier.predict(X_test)    \n",
    "        y_proba_concat[cname]['normal'] = np.concatenate((y_proba_concat[cname]['normal'],y_proba))\n",
    "        y_test_concat[cname]['normal'] = np.concatenate((y_test_concat[cname]['normal'],y_test))\n",
    "        y_pred_concat[cname]['normal'] = np.concatenate((y_pred_concat[cname]['normal'],y_pred))\n",
    "\n",
    "        # oversample\n",
    "        classifier = clone(c)\n",
    "        classifier.fit(X_over, y_over)\n",
    "        y_proba = classifier.predict_proba(X_test)\n",
    "        y_pred = classifier.predict(X_test)    \n",
    "        y_proba_concat[cname]['over'] = np.concatenate((y_proba_concat[cname]['over'],y_proba))\n",
    "        y_test_concat[cname]['over'] = np.concatenate((y_test_concat[cname]['over'],y_test))\n",
    "        y_pred_concat[cname]['over'] = np.concatenate((y_pred_concat[cname]['over'],y_pred))\n",
    "\n",
    "        # undersample\n",
    "        classifier = clone(c)\n",
    "        classifier.fit(X_under, y_under)\n",
    "        y_proba = classifier.predict_proba(X_test)\n",
    "        y_pred = classifier.predict(X_test)    \n",
    "        y_proba_concat[cname]['under'] = np.concatenate((y_proba_concat[cname]['under'],y_proba))\n",
    "        y_test_concat[cname]['under'] = np.concatenate((y_test_concat[cname]['under'],y_test))\n",
    "        y_pred_concat[cname]['under'] = np.concatenate((y_pred_concat[cname]['under'],y_pred))\n",
    "\n",
    "        # smote\n",
    "        classifier = clone(c)\n",
    "        classifier.fit(X_smote, y_smote)\n",
    "        y_proba = classifier.predict_proba(X_test)\n",
    "        y_pred = classifier.predict(X_test)    \n",
    "        y_proba_concat[cname]['smote'] = np.concatenate((y_proba_concat[cname]['smote'],y_proba))\n",
    "        y_test_concat[cname]['smote'] = np.concatenate((y_test_concat[cname]['smote'],y_test))\n",
    "        y_pred_concat[cname]['smote'] = np.concatenate((y_pred_concat[cname]['smote'],y_pred))\n",
    "\n",
    "        # Blagging\n",
    "        classifier = clone(c)\n",
    "        bc = OneVsRestClassifier(BlaggingClassifier(classifier))\n",
    "        bc.fit(X_train,y_train)\n",
    "        y_proba = bc.predict_proba(X_test)\n",
    "        y_pred = bc.predict(X_test)\n",
    "        y_proba_concat[cname]['blagging'] = np.concatenate((y_proba_concat[cname]['blagging'],y_proba))\n",
    "        y_test_concat[cname]['blagging'] = np.concatenate((y_test_concat[cname]['blagging'],y_test))\n",
    "        y_pred_concat[cname]['blagging'] = np.concatenate((y_pred_concat[cname]['blagging'],y_pred))\n",
    "        \n",
    "        # weighted\n",
    "        if cname in  ['logistic', 'dTree', 'rForest', 'svm']:\n",
    "            classifier = clone(c)\n",
    "            classifier.set_params(class_weight = 'balanced')\n",
    "            classifier.fit(X_train, y_train)\n",
    "            y_proba = classifier.predict_proba(X_test)\n",
    "            y_pred = classifier.predict(X_test)    \n",
    "            y_proba_concat[cname]['weighted'] = np.concatenate((y_proba_concat[cname]['weighted'],y_proba))\n",
    "            y_test_concat[cname]['weighted'] = np.concatenate((y_test_concat[cname]['weighted'],y_test))\n",
    "            y_pred_concat[cname]['weighted'] = np.concatenate((y_pred_concat[cname]['weighted'],y_pred))\n",
    "\n",
    "c = np.unique(y_test_concat['logistic']['normal'])\n",
    "for cname in  ['knn', 'gnb', 'logistic', 'lda', 'qda', 'dTree', 'rForest', 'svm', 'adaBoost']:\n",
    "    for k in ['normal','over','under','smote','blagging','weighted']:\n",
    "        if k == 'weighted' and cname not in  ['logistic', 'dTree', 'rForest', 'svm']:\n",
    "            continue\n",
    "        else:\n",
    "            y_test_concat[cname][k] = label_binarize(y_test_concat[cname][k], classes=c)\n",
    "            y_pred_concat[cname][k] = label_binarize(y_pred_concat[cname][k], classes=c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leen/virtualEnv/myenv/local/lib/python2.7/site-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "fpr = dict()\n",
    "tpr = dict()\n",
    "thresholds = dict()\n",
    "roc_auc = dict()\n",
    "accuracy = dict()\n",
    "f_measure = dict()\n",
    "\n",
    "for cname in ['knn', 'gnb', 'logistic', 'lda', 'qda', 'dTree', 'rForest', 'svm', 'adaBoost']:\n",
    "    fpr[cname] = dict()\n",
    "    tpr[cname] = dict()\n",
    "    thresholds[cname] = dict()\n",
    "    roc_auc[cname] = dict()\n",
    "    accuracy[cname] = dict()\n",
    "    f_measure[cname] = dict()\n",
    "    for k in ['normal','over','under','smote','blagging','weighted']:\n",
    "        if k == 'weighted' and cname not in  ['logistic', 'dTree', 'rForest', 'svm']:\n",
    "            continue\n",
    "        else:\n",
    "            # Compute ROC curve and ROC area for each class\n",
    "            fpr[cname][k] = dict()\n",
    "            tpr[cname][k] = dict()\n",
    "            thresholds[cname][k] = dict()\n",
    "            roc_auc[cname][k] = dict()\n",
    "            accuracy[cname][k] = dict()\n",
    "            f_measure[cname][k] = dict()\n",
    "            for i in range(11):\n",
    "                fpr[cname][k][Mapping[i]], tpr[cname][k][Mapping[i]], thresholds[cname][k][Mapping[i]] = roc_curve(y_test_concat[cname][k][:, i], np.nan_to_num(y_proba_concat[cname][k][:, i]))\n",
    "                roc_auc[cname][k][Mapping[i]] = auc(fpr[cname][k][Mapping[i]], tpr[cname][k][Mapping[i]])\n",
    "\n",
    "                accuracy[cname][k][Mapping[i]] = accuracy_score(y_test_concat[cname][k][:, i], y_pred_concat[cname][k][:, i])\n",
    "                f_measure[cname][k][Mapping[i]] = f1_score(y_test_concat[cname][k][:,i], y_pred_concat[cname][k][:,i])\n",
    "\n",
    "            # Compute micro-average ROC curve and ROC area\n",
    "            fpr[cname][k][\"micro\"], tpr[cname][k][\"micro\"], thresholds[cname][k][\"micro\"] = roc_curve(y_test_concat[cname][k].ravel(), np.nan_to_num(y_proba_concat[cname][k].ravel()))\n",
    "            roc_auc[cname][k][\"micro\"] = auc(fpr[cname][k][\"micro\"], tpr[cname][k][\"micro\"])\n",
    "            accuracy[cname][k][\"micro\"] = accuracy_score(y_test_concat[cname][k].ravel(), y_pred_concat[cname][k].ravel())\n",
    "            f_measure[cname][k][\"micro\"] = f1_score(y_test_concat[cname][k].ravel(), y_pred_concat[cname][k].ravel())\n",
    "\n",
    "\n",
    "            # First aggregate all false positive rates\n",
    "            all_fpr = np.unique(np.concatenate([fpr[cname][k][Mapping[i]] for i in range(11)]))\n",
    "\n",
    "            # Then interpolate all ROC curves at this points\n",
    "            mean_tpr = np.zeros_like(all_fpr)\n",
    "            mean_acc = 0\n",
    "            mean_f = 0\n",
    "            for i in range(11):\n",
    "                mean_tpr += interp(all_fpr, fpr[cname][k][Mapping[i]], tpr[cname][k][Mapping[i]])\n",
    "                mean_acc += accuracy[cname][k][Mapping[i]]\n",
    "                mean_f += f_measure[cname][k][Mapping[i]]\n",
    "\n",
    "            # Finally average it and compute AUC\n",
    "            mean_tpr /= 11\n",
    "\n",
    "            fpr[cname][k][\"macro\"] = all_fpr\n",
    "            tpr[cname][k][\"macro\"] = mean_tpr\n",
    "            roc_auc[cname][k][\"macro\"] = auc(fpr[cname][k][\"macro\"], tpr[cname][k][\"macro\"])\n",
    "            accuracy[cname][k][\"macro\"] = mean_acc / 11\n",
    "            f_measure[cname][k][\"macro\"] = mean_f / 11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Air Conditioner (208)\n",
      "AUC\n",
      "# h \tnormal\tover\tunder\tsmote\tblagging\tweighted\n",
      "knn & $ 52.30$ & $-0.03$ & $0.33$ & $0.27$ & $15.47$ \\\\ \n",
      "gnb & $ 78.14$ & $-0.01$ & $-11.18$ & $-0.05$ & $0.24$ \\\\ \n",
      "logistic & $ 65.62$ & $0.84$ & $-4.53$ & $1.88$ & $-1.36$ & $0.33$ \\\\ \n",
      "lda & $ 60.23$ & $-5.81$ & $-1.95$ & $-5.92$ & $6.20$ \\\\ \n",
      "qda & $ 51.70$ & $-6.77$ & $-1.97$ & $-6.76$ & $-1.70$ \\\\ \n",
      "dTree & $ 46.82$ & $0.09$ & $5.71$ & $7.54$ & $25.19$ & $3.51$ \\\\ \n",
      "rForest & $ 73.59$ & $-2.16$ & $-6.50$ & $-2.74$ & $-1.65$ & $-1.35$ \\\\ \n",
      "svm & $ 78.98$ & $-2.99$ & $-4.19$ & $-2.61$ & $-10.43$ & $-2.36$ \\\\ \n",
      "adaBoost & $ 60.25$ & $1.83$ & $2.85$ & $2.16$ & $10.89$ \\\\ \n",
      "\n",
      "Compact Fluorescent Lamp (220)\n",
      "AUC\n",
      "# h \tnormal\tover\tunder\tsmote\tblagging\tweighted\n",
      "knn & $ 96.75$ & $0.00$ & $-2.56$ & $0.03$ & $0.86$ \\\\ \n",
      "gnb & $ 97.46$ & $0.00$ & $-4.48$ & $0.00$ & $2.25$ \\\\ \n",
      "logistic & $ 99.05$ & $0.18$ & $-0.19$ & $0.25$ & $0.40$ & $-0.03$ \\\\ \n",
      "lda & $ 81.72$ & $-5.51$ & $2.16$ & $-5.76$ & $17.93$ \\\\ \n",
      "qda & $ 49.94$ & $16.08$ & $1.27$ & $15.73$ & $0.06$ \\\\ \n",
      "dTree & $ 94.61$ & $1.34$ & $-6.30$ & $2.14$ & $4.94$ & $-0.10$ \\\\ \n",
      "rForest & $ 97.65$ & $0.39$ & $0.95$ & $0.36$ & $2.11$ & $0.19$ \\\\ \n",
      "svm & $ 99.69$ & $-0.09$ & $-0.01$ & $-0.15$ & $-0.12$ & $-0.22$ \\\\ \n",
      "adaBoost & $ 94.21$ & $2.75$ & $-4.19$ & $1.02$ & $5.60$ \\\\ \n",
      "\n",
      "Fan (210)\n",
      "AUC\n",
      "# h \tnormal\tover\tunder\tsmote\tblagging\tweighted\n",
      "knn & $ 69.86$ & $-0.03$ & $-1.76$ & $-0.83$ & $11.97$ \\\\ \n",
      "gnb & $ 68.15$ & $-0.16$ & $-8.98$ & $0.50$ & $9.06$ \\\\ \n",
      "logistic & $ 76.92$ & $0.02$ & $-5.24$ & $-0.37$ & $-2.07$ & $-0.06$ \\\\ \n",
      "lda & $ 55.94$ & $0.24$ & $8.99$ & $-1.68$ & $20.73$ \\\\ \n",
      "qda & $ 51.98$ & $-1.25$ & $1.14$ & $-2.17$ & $-1.98$ \\\\ \n",
      "dTree & $ 63.38$ & $6.95$ & $0.38$ & $6.40$ & $16.52$ & $5.34$ \\\\ \n",
      "rForest & $ 82.44$ & $0.95$ & $-5.91$ & $0.68$ & $-0.51$ & $2.71$ \\\\ \n",
      "svm & $ 84.17$ & $-1.21$ & $-5.59$ & $-2.64$ & $-8.68$ & $-0.47$ \\\\ \n",
      "adaBoost & $ 66.85$ & $1.66$ & $1.53$ & $-7.65$ & $11.99$ \\\\ \n",
      "\n",
      "Fridge (90)\n",
      "AUC\n",
      "# h \tnormal\tover\tunder\tsmote\tblagging\tweighted\n",
      "knn & $ 71.13$ & $0.03$ & $-6.84$ & $1.40$ & $11.72$ \\\\ \n",
      "gnb & $ 78.14$ & $1.02$ & $-8.79$ & $0.05$ & $0.42$ \\\\ \n",
      "logistic & $ 76.35$ & $0.23$ & $-3.48$ & $0.89$ & $7.50$ & $0.05$ \\\\ \n",
      "lda & $ 51.41$ & $1.54$ & $10.46$ & $-0.69$ & $35.38$ \\\\ \n",
      "qda & $ 52.50$ & $-0.78$ & $-3.14$ & $-0.99$ & $-2.50$ \\\\ \n",
      "dTree & $ 59.38$ & $8.55$ & $-2.12$ & $6.53$ & $23.66$ & $5.91$ \\\\ \n",
      "rForest & $ 88.23$ & $-0.72$ & $-11.69$ & $-0.73$ & $-2.49$ & $-0.57$ \\\\ \n",
      "svm & $ 86.20$ & $-2.15$ & $-9.91$ & $-1.45$ & $-2.43$ & $0.75$ \\\\ \n",
      "adaBoost & $ 61.11$ & $-4.32$ & $5.28$ & $6.42$ & $22.05$ \\\\ \n",
      "\n",
      "Hairdryer (248)\n",
      "AUC\n",
      "# h \tnormal\tover\tunder\tsmote\tblagging\tweighted\n",
      "knn & $ 78.55$ & $14.33$ & $-6.75$ & $15.78$ & $17.11$ \\\\ \n",
      "gnb & $ 62.33$ & $-0.06$ & $6.16$ & $-0.07$ & $25.05$ \\\\ \n",
      "logistic & $ 93.67$ & $0.31$ & $-3.54$ & $-0.99$ & $-0.07$ & $0.63$ \\\\ \n",
      "lda & $ 77.93$ & $-3.10$ & $-0.65$ & $-2.38$ & $15.37$ \\\\ \n",
      "qda & $ 52.45$ & $25.21$ & $-2.45$ & $27.35$ & $-2.45$ \\\\ \n",
      "dTree & $ 90.43$ & $0.43$ & $-7.22$ & $1.13$ & $3.42$ & $-1.37$ \\\\ \n",
      "rForest & $ 96.53$ & $0.23$ & $-2.85$ & $-0.05$ & $-2.33$ & $-0.02$ \\\\ \n",
      "svm & $ 94.37$ & $0.89$ & $-1.89$ & $0.10$ & $-2.17$ & $-0.61$ \\\\ \n",
      "adaBoost & $ 62.69$ & $5.79$ & $11.82$ & $3.94$ & $31.64$ \\\\ \n",
      "\n",
      "Heater (85)\n",
      "AUC\n",
      "# h \tnormal\tover\tunder\tsmote\tblagging\tweighted\n",
      "knn & $ 83.05$ & $-18.43$ & $-19.91$ & $-12.60$ & $9.22$ \\\\ \n",
      "gnb & $ 86.26$ & $0.00$ & $-0.20$ & $0.00$ & $2.03$ \\\\ \n",
      "logistic & $ 92.45$ & $2.43$ & $2.67$ & $1.86$ & $2.48$ & $1.03$ \\\\ \n",
      "lda & $ 70.40$ & $1.12$ & $0.56$ & $2.85$ & $23.30$ \\\\ \n",
      "qda & $ 50.00$ & $29.88$ & $4.49$ & $29.88$ & $0.00$ \\\\ \n",
      "dTree & $ 87.66$ & $-0.97$ & $-1.00$ & $-2.61$ & $5.44$ & $-4.29$ \\\\ \n",
      "rForest & $ 92.03$ & $2.07$ & $2.87$ & $0.29$ & $0.54$ & $1.83$ \\\\ \n",
      "svm & $ 93.81$ & $0.26$ & $-1.48$ & $-2.18$ & $0.33$ & $-2.58$ \\\\ \n",
      "adaBoost & $ 88.62$ & $0.84$ & $-17.00$ & $2.35$ & $5.49$ \\\\ \n",
      "\n",
      "Incandescent Light Bulb (148)\n",
      "AUC\n",
      "# h \tnormal\tover\tunder\tsmote\tblagging\tweighted\n",
      "knn & $ 81.25$ & $0.03$ & $-3.56$ & $-1.60$ & $13.25$ \\\\ \n",
      "gnb & $ 91.01$ & $-0.00$ & $-5.64$ & $0.00$ & $2.09$ \\\\ \n",
      "logistic & $ 89.00$ & $-0.02$ & $3.27$ & $-0.30$ & $7.17$ & $0.01$ \\\\ \n",
      "lda & $ 50.66$ & $-6.88$ & $3.60$ & $-7.04$ & $44.19$ \\\\ \n",
      "qda & $ 48.04$ & $7.09$ & $0.71$ & $6.08$ & $1.96$ \\\\ \n",
      "dTree & $ 86.66$ & $0.04$ & $-9.60$ & $-4.91$ & $8.73$ & $-1.39$ \\\\ \n",
      "rForest & $ 96.24$ & $0.30$ & $-0.70$ & $0.34$ & $0.56$ & $-0.52$ \\\\ \n",
      "svm & $ 97.51$ & $-0.33$ & $-0.01$ & $-0.13$ & $0.44$ & $0.12$ \\\\ \n",
      "adaBoost & $ 82.99$ & $0.69$ & $-3.11$ & $3.92$ & $12.46$ \\\\ \n",
      "\n",
      "Laptop (207)\n",
      "AUC\n",
      "# h \tnormal\tover\tunder\tsmote\tblagging\tweighted\n",
      "knn & $ 94.98$ & $-0.72$ & $-8.19$ & $-1.08$ & $2.21$ \\\\ \n",
      "gnb & $ 91.39$ & $-0.00$ & $-7.28$ & $0.03$ & $2.82$ \\\\ \n",
      "logistic & $ 95.22$ & $-0.16$ & $-4.39$ & $-0.71$ & $1.72$ & $0.02$ \\\\ \n",
      "lda & $ 22.35$ & $5.19$ & $4.59$ & $5.77$ & $74.34$ \\\\ \n",
      "qda & $ 53.38$ & $13.83$ & $2.11$ & $12.61$ & $-3.38$ \\\\ \n",
      "dTree & $ 89.54$ & $0.39$ & $-7.81$ & $-1.05$ & $7.67$ & $1.06$ \\\\ \n",
      "rForest & $ 96.95$ & $1.36$ & $-2.93$ & $-0.58$ & $-0.27$ & $0.35$ \\\\ \n",
      "svm & $ 98.73$ & $-0.21$ & $-6.10$ & $-0.27$ & $-2.77$ & $-0.14$ \\\\ \n",
      "adaBoost & $ 79.43$ & $2.71$ & $1.57$ & $-1.20$ & $16.48$ \\\\ \n",
      "\n",
      "Microwave (229)\n",
      "AUC\n",
      "# h \tnormal\tover\tunder\tsmote\tblagging\tweighted\n",
      "knn & $ 94.50$ & $0.00$ & $-3.37$ & $-0.37$ & $3.32$ \\\\ \n",
      "gnb & $ 94.08$ & $0.01$ & $-17.16$ & $0.01$ & $-0.98$ \\\\ \n",
      "logistic & $ 97.77$ & $0.07$ & $-2.01$ & $0.02$ & $-0.33$ & $-0.02$ \\\\ \n",
      "lda & $ 36.58$ & $2.69$ & $-6.11$ & $3.36$ & $60.72$ \\\\ \n",
      "qda & $ 49.99$ & $5.01$ & $3.15$ & $6.17$ & $0.01$ \\\\ \n",
      "dTree & $ 83.29$ & $0.90$ & $-12.14$ & $5.19$ & $12.17$ & $-3.53$ \\\\ \n",
      "rForest & $ 98.56$ & $-0.21$ & $-3.11$ & $0.35$ & $-0.69$ & $0.16$ \\\\ \n",
      "svm & $ 99.31$ & $-0.06$ & $-4.76$ & $-0.05$ & $-0.94$ & $-0.13$ \\\\ \n",
      "adaBoost & $ 68.47$ & $12.69$ & $-1.84$ & $4.88$ & $27.14$ \\\\ \n",
      "\n",
      "Vacuum (73)\n",
      "AUC\n",
      "# h \tnormal\tover\tunder\tsmote\tblagging\tweighted\n",
      "knn & $ 99.33$ & $0.00$ & $-0.52$ & $-0.09$ & $-0.62$ \\\\ \n",
      "gnb & $ 89.73$ & $0.00$ & $-1.37$ & $0.00$ & $1.30$ \\\\ \n",
      "logistic & $ 99.88$ & $-0.02$ & $-0.42$ & $0.08$ & $0.02$ & $-0.00$ \\\\ \n",
      "lda & $ 83.80$ & $-1.34$ & $-8.96$ & $-0.98$ & $16.12$ \\\\ \n",
      "qda & $ 54.11$ & $6.85$ & $7.31$ & $5.48$ & $-4.11$ \\\\ \n",
      "dTree & $ 95.28$ & $-1.10$ & $2.41$ & $-0.68$ & $4.56$ & $-0.51$ \\\\ \n",
      "rForest & $ 99.99$ & $-0.01$ & $-0.03$ & $-0.02$ & $-0.01$ & $-0.01$ \\\\ \n",
      "svm & $ 99.98$ & $0.00$ & $-0.04$ & $0.00$ & $-0.00$ & $0.00$ \\\\ \n",
      "adaBoost & $ 83.12$ & $6.39$ & $-1.16$ & $7.50$ & $16.65$ \\\\ \n",
      "\n",
      "Washing Machine (75)\n",
      "AUC\n",
      "# h \tnormal\tover\tunder\tsmote\tblagging\tweighted\n",
      "knn & $ 79.88$ & $-0.12$ & $0.34$ & $2.17$ & $9.09$ \\\\ \n",
      "gnb & $ 86.72$ & $-0.05$ & $-1.77$ & $-0.07$ & $0.21$ \\\\ \n",
      "logistic & $ 90.40$ & $-0.10$ & $-0.04$ & $0.89$ & $-2.54$ & $-0.10$ \\\\ \n",
      "lda & $ 63.35$ & $-6.49$ & $-3.83$ & $-5.30$ & $26.53$ \\\\ \n",
      "qda & $ 49.39$ & $0.99$ & $5.35$ & $3.65$ & $0.61$ \\\\ \n",
      "dTree & $ 78.86$ & $-10.38$ & $-8.16$ & $-8.76$ & $8.61$ & $-9.34$ \\\\ \n",
      "rForest & $ 89.92$ & $0.93$ & $2.67$ & $1.84$ & $0.76$ & $2.05$ \\\\ \n",
      "svm & $ 91.88$ & $0.61$ & $0.18$ & $0.99$ & $-1.11$ & $1.06$ \\\\ \n",
      "adaBoost & $ 75.83$ & $-1.46$ & $-3.49$ & $-5.72$ & $14.44$ \\\\ \n",
      "\n",
      "macro (0)\n",
      "AUC\n",
      "# h \tnormal\tover\tunder\tsmote\tblagging\tweighted\n",
      "knn & $ 81.96$ & $-0.45$ & $-4.80$ & $0.28$ & $8.51$ \\\\ \n",
      "gnb & $ 83.95$ & $0.07$ & $-5.52$ & $0.03$ & $4.05$ \\\\ \n",
      "logistic & $ 88.76$ & $0.34$ & $-1.63$ & $0.32$ & $1.17$ & $0.17$ \\\\ \n",
      "lda & $ 59.49$ & $-1.67$ & $0.81$ & $-1.62$ & $30.99$ \\\\ \n",
      "qda & $ 51.23$ & $8.74$ & $1.63$ & $8.82$ & $-1.23$ \\\\ \n",
      "dTree & $ 79.63$ & $0.56$ & $-4.17$ & $0.99$ & $10.99$ & $-0.43$ \\\\ \n",
      "rForest & $ 92.02$ & $0.29$ & $-2.48$ & $-0.02$ & $-0.36$ & $0.44$ \\\\ \n",
      "svm & $ 93.16$ & $-0.48$ & $-3.07$ & $-0.76$ & $-2.54$ & $-0.42$ \\\\ \n",
      "adaBoost & $ 74.88$ & $2.69$ & $-0.71$ & $1.60$ & $15.89$ \\\\ \n",
      "\n",
      "micro (0)\n",
      "AUC\n",
      "# h \tnormal\tover\tunder\tsmote\tblagging\tweighted\n",
      "knn & $ 81.47$ & $1.29$ & $-4.36$ & $1.60$ & $10.85$ \\\\ \n",
      "gnb & $ 84.31$ & $0.03$ & $-6.94$ & $0.03$ & $4.85$ \\\\ \n",
      "logistic & $ 88.40$ & $0.02$ & $-2.33$ & $-0.16$ & $4.17$ & $0.09$ \\\\ \n",
      "lda & $ 54.24$ & $-0.69$ & $0.48$ & $-0.65$ & $38.81$ \\\\ \n",
      "qda & $ 51.31$ & $10.19$ & $0.74$ & $10.17$ & $-1.31$ \\\\ \n",
      "dTree & $ 80.36$ & $0.94$ & $-5.35$ & $2.03$ & $11.48$ & $0.06$ \\\\ \n",
      "rForest & $ 93.99$ & $0.04$ & $-3.66$ & $-0.29$ & $-0.68$ & $-0.15$ \\\\ \n",
      "svm & $ 95.57$ & $-0.75$ & $-2.69$ & $-1.09$ & $-1.74$ & $-0.18$ \\\\ \n",
      "adaBoost & $ 78.85$ & $0.88$ & $-4.09$ & $-1.09$ & $13.87$ \\\\ \n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "\n",
    "i_values = Mapping.values()[:] \n",
    "i_values.extend(['macro', 'micro'])\n",
    "\n",
    "for i in i_values:\n",
    "    to_print = \"\"\n",
    "    to_print1 = \"\"\n",
    "    to_print2 = \"\"\n",
    "    for  cname in  ['knn', 'gnb', 'logistic', 'lda', 'qda', 'dTree', 'rForest', 'svm','adaBoost']:\n",
    "        to_print += str(cname) + \" & $ \"\n",
    "        for k in ['normal','over','under','smote','blagging','weighted']:     \n",
    "            if k == 'weighted' and cname not in  ['logistic', 'dTree', 'rForest', 'svm']:\n",
    "                to_print += \"\"\n",
    "                continue\n",
    "            else:\n",
    "                if k == 'normal':\n",
    "                    to_print += \"{0:.2f}\".format(roc_auc[cname][k][i] *  100) + \"$ & $\"\n",
    "                else:\n",
    "                    to_print += \"{0:.2f}\".format(roc_auc[cname][k][i] * 100 - roc_auc[cname]['normal'][i] * 100 ) + \"$ & $\"\n",
    "\n",
    "        to_print = to_print[:-3]\n",
    "        to_print += \"\\\\\\\\ \\n\"\n",
    "\n",
    "    print(\"{} ({})\".format(i, sum(np.array(Types) == i)) )\n",
    "    print(\"AUC\")\n",
    "    print(\"# h \\tnormal\\tover\\tunder\\tsmote\\tblagging\\tweighted\")\n",
    "    print(to_print)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
